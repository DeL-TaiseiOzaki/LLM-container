# lora_finetuning_config.yaml
base:
  image: "nvcr.io/nvidia/pytorch"
  tag: "24.05-py3"  # 最新のNVIDIA PyTorchコンテナを使用
  cuda_version: "12.8"  # 環境に合わせたCUDAバージョン
  python_version: "3.10"  # 安定したPythonバージョン

gpu:
  architecture: "hopper"  # H100はHopperアーキテクチャ
  count: 4  # 4基のGPUを全て使用
  multi_node: false  # 単一ノード内のマルチGPU
  optimization: true  # GPUパフォーマンス最適化を有効化

deep_learning:
  pytorch:
    version: ""  # 空でも問題なく、CUDA依存で最新が選択される
    source: "pip"
    cuda_specific: true
    extras: ["torchvision", "torchaudio"]
  
  attention:
    flash_attention: true  # trueの場合、バージョン無指定でインストール
    flash_attention_version: ""  # 空のままでOK
    xformers: true
    xformers_version: "0.0.30"  
    triton: true

claude_code:
  install: true  # Anthropicの開発支援AIツールを統合
  version: "latest"

libraries:
  use_preset: false  # カスタムライブラリを使用
  custom:
    lora:  # LoRA/PEFT特化のライブラリ
      - {"name": "transformers", "version": ">=4.41.0"}
      - {"name": "peft", "version": ">=0.10.0"}  # LoRA実装
      - {"name": "accelerate", "version": ">=0.29.3"}  # 分散トレーニング
      - {"name": "deepspeed", "install": true}  # ZeRO最適化
      - {"name": "bitsandbytes", "version": ""}  # 量子化
      - {"name": "trl", "version": ">=0.10.0"}  # 強化学習フレームワーク
      - {"name": "packaging", "install": true}  # バージョン指定なし
      - {"name": "ninja", "install": true}    # バージョン指定なし

    
    data:  # データ処理ライブラリ
      - {"name": "datasets", "install": true}
      - {"name": "huggingface_hub", "install": true}
      - {"name": "sentencepiece", "install": true}
      - {"name": "tokenizers", "install": true}
      - {"name": "safetensors", "install": true}
      - {"name": "evaluate", "install": true}
    
    utils:  # ユーティリティライブラリ
      - {"name": "numpy", "install": true}
      - {"name": "pandas", "install": true}
      - {"name": "wandb", "install": true} 
      - {"name": "jupyterlab", "install": true}
      - {"name": "ipywidgets", "install": true}
      - {"name": "tqdm", "install": true}
      - {"name": "einops", "install": true}  # テンソル操作

environment:
  preset:
    hopper: true  # H100向けの最適化設定
    multi_gpu: true  # マルチGPU環境設定を有効化
  
  custom:
    - {"name": "PYTORCH_CUDA_ALLOC_CONF", "value": "max_split_size_mb:512"}
    - {"name": "NCCL_DEBUG", "value": "INFO"}
    - {"name": "NCCL_P2P_LEVEL", "value": "NVL"}
    - {"name": "NCCL_IB_DISABLE", "value": "0"}
    - {"name": "NCCL_SOCKET_IFNAME", "value": "^lo,docker"}
    - {"name": "OMP_NUM_THREADS", "value": "8"}
    - {"name": "CUDA_DEVICE_MAX_CONNECTIONS", "value": "1"}

workspace:
  directory: "/mnt"  # データマウント先

distributed:
  enable: true  # 分散トレーニングを有効化
  backend: "nccl"  # NVIDIAのCUDA通信ライブラリ
  init_method: "env://"