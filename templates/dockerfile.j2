# 自動生成されたDockerfile - {{ timestamp }}
FROM {{ base.image }}:{{ base.tag }}

# ────────────── 基本 ENV ──────────────
ENV BNB_CUDA_VERSION={{ base.cuda_version | replace(".", "") }}
ENV PYTHONUNBUFFERED=1
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}

# ────────────── uv設定 ──────────────
ENV UV_SYSTEM_PYTHON=1
ENV UV_CACHE_DIR=/opt/uv-cache
ENV UV_NO_PROGRESS=1

# ────────────── PEP 668制限の無効化 ──────────────
# Docker環境ではexternally managed制限を無効化
RUN rm -f /usr/lib/python*/EXTERNALLY-MANAGED
ENV PIP_BREAK_SYSTEM_PACKAGES=1

# ────────────── OS パッケージ ──────────────
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl ca-certificates git build-essential cmake ninja-build wget \
    && rm -rf /var/lib/apt/lists/*

# ────────────── uv インストール ──────────────
RUN curl -LsSf https://astral.sh/uv/install.sh | sh
ENV PATH="/root/.local/bin:${PATH}"

# uvのキャッシュディレクトリを作成
RUN mkdir -p ${UV_CACHE_DIR}

# uvインストール確認
RUN uv --version

{% if claude_code.install %}
# ────────────── Node.js ──────────────
RUN curl -fsSL https://deb.nodesource.com/setup_lts.x | bash - && \
    apt-get install -y nodejs && \
    npm install -g @anthropic-ai/claude-code
{% endif %}

# ────────────── PyTorch ──────────────
{% if deep_learning.pytorch.source == "pip" %}
# 既存のPyTorchを削除
RUN uv pip uninstall torch torchvision torchaudio || true

# PyTorchをuvでインストール（バージョン指定なし・CUDA自動選択）
RUN uv pip install \
    torch \
    torchvision \
    torchaudio \
    --index-url https://download.pytorch.org/whl/cu124
{% endif %}

# ────────────── bitsandbytes（ソースからビルド） ──────────────
RUN git clone --depth 1 https://github.com/bitsandbytes-foundation/bitsandbytes.git && \
    cd bitsandbytes && \
    export BNB_CUDA_VERSION={{ base.cuda_version | replace(".", "") }} && \
    cmake -DCOMPUTE_BACKEND=cuda -S . && \
    make -j$(nproc) && \
    pip install -e . && \
    cd .. && rm -rf bitsandbytes

{% if deep_learning.attention.xformers %}
# ────────────── xformers ──────────────
RUN uv pip install xformers
{% endif %}

{% if deep_learning.attention.flash_attention %}
# ────────────── Flash-Attention ──────────────
# ビルド依存関係をuvでインストール
RUN uv pip install ninja packaging wheel setuptools

# Flash Attentionのビルドとインストール
RUN TORCH_CUDA_ARCH_LIST="{{ gpu_arch_list|default('8.0;8.6;9.0') }}" \
    MAX_JOBS=$(nproc) \
    uv pip install flash-attn=={{ deep_learning.attention.flash_attention_version }} \
    --no-build-isolation
{% endif %}

{% if deep_learning.attention.triton %}
# ────────────── Triton ──────────────
RUN uv pip install \
    --index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/Triton-Nightly/pypi/simple/ \
    triton-nightly
{% endif %}

# ────────────── ライブラリの一括インストール ──────────────
{% if libraries_flat %}
{% for lib in libraries_flat %}
{%- if lib.source is defined %}
RUN uv pip install "{{ lib.source }}"
{%- elif lib.version is defined %}
RUN uv pip install "{{ lib.name }}{{ lib.version }}{% if lib.extra is defined %}[{{ lib.extra }}]{% endif %}"
{%- elif lib.install is defined and lib.install %}
RUN uv pip install "{{ lib.name }}{% if lib.extra is defined %}[{{ lib.extra }}]{% endif %}"
{%- endif %}
{% endfor %}
{% endif %}

# ────────────── uvキャッシュの最適化 ──────────────
RUN uv cache clean

# ────────────── 分散設定 ──────────────
ENV MASTER_ADDR=localhost
ENV MASTER_PORT=29500
ENV WORLD_SIZE={{ gpu.count }}

# ────────────── カスタム ENV ──────────────
{% for env_var in env_vars %}
ENV {{ env_var.name }}={{ env_var.value }}
{% endfor %}

WORKDIR {{ workspace.directory }}

# パッケージリストを記録
RUN uv pip list > /installed-packages.txt

# ヘルスチェック用スクリプト
RUN echo '#!/bin/bash\npython -c "import torch; assert torch.cuda.is_available()"' > /healthcheck.sh && \
    chmod +x /healthcheck.sh

HEALTHCHECK --interval=30s --timeout=10s --start-period=30s --retries=3 \
    CMD /healthcheck.sh || exit 1