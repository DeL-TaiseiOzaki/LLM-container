# Simple LLM Docker Environment
# Generated: {{ timestamp }}

FROM nvidia/cuda:12.8.0-cudnn-devel-ubuntu22.04

# åŸºæœ¬è¨­å®š
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}

# Python {{ python_version }} ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN apt-get update && apt-get install -y \
    software-properties-common \
    && add-apt-repository ppa:deadsnakes/ppa \
    && apt-get update && apt-get install -y \
    python{{ python_version }} \
    python{{ python_version }}-dev \
    python{{ python_version }}-venv \
    python3-pip \
    curl wget git build-essential \
    && rm -rf /var/lib/apt/lists/*

# Python {{ python_version }} ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
RUN update-alternatives --install /usr/bin/python python /usr/bin/python{{ python_version }} 1 \
    && update-alternatives --install /usr/bin/python3 python3 /usr/bin/python{{ python_version }} 1

# uv ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆé«˜é€Ÿãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒžãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼‰
RUN curl -LsSf https://astral.sh/uv/install.sh | sh
ENV PATH="/root/.local/bin:${PATH}"
ENV UV_SYSTEM_PYTHON=1

# uvã®ç¢ºèª
RUN uv --version

{% if claude_code %}
# Claude Code ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN curl -fsSL https://deb.nodesource.com/setup_lts.x | bash - \
    && apt-get install -y nodejs \
    && npm install -g @anthropic-ai/claude-code
{% endif %}

# PyTorch ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
RUN uv pip install torch=={{ pytorch_version }} torchvision torchaudio \
    --index-url {{ pytorch_index_url }}

# Transformers ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆå¿…é ˆï¼‰
RUN uv pip install transformers=={{ transformers_version }}

# ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
{% if packages.vllm %}
RUN uv pip install vllm
{% endif %}

{% if packages.trl %}
RUN uv pip install trl
{% endif %}

{% if packages.unsloth %}
RUN uv pip install "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"
{% endif %}

{% if packages.deepspeed %}
RUN uv pip install deepspeed
{% endif %}

{% if packages.flash_attention2 %}
RUN uv pip install ninja packaging wheel
RUN MAX_JOBS=4 uv pip install flash-attn --no-build-isolation
{% endif %}

{% if packages.openai %}
RUN uv pip install openai
{% endif %}

{% if packages.litellm %}
RUN uv pip install litellm
{% endif %}

{% if packages.langchain %}
RUN uv pip install langchain langchain-community
{% endif %}

{% if jupyter %}
# Jupyter Lab
RUN uv pip install jupyterlab ipywidgets
{% endif %}

# åŸºæœ¬çš„ãªMLãƒ„ãƒ¼ãƒ«
RUN uv pip install \
    numpy \
    pandas \
    matplotlib \
    tqdm \
    accelerate \
    datasets \
    huggingface-hub

# ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
WORKDIR {{ mount_path }}

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
RUN echo '#!/bin/bash\npython -c "import torch; print(f\"PyTorch {torch.__version__}\"); print(f\"CUDA available: {torch.cuda.is_available()}\")"' > /healthcheck.sh \
    && chmod +x /healthcheck.sh

# èµ·å‹•æ™‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
RUN echo '#!/bin/bash\n\
echo "========================================"\n\
echo "ðŸš€ Simple LLM Docker Environment"\n\
echo "========================================"\n\
echo "ðŸ“¦ Versions:"\n\
echo "  CUDA: {{ cuda_version }}"\n\
echo "  Python: {{ python_version }}"\n\
echo "  PyTorch: {{ pytorch_version }}"\n\
echo "  Transformers: {{ transformers_version }}"\n\
echo "========================================"\n\
python /healthcheck.sh\n\
echo "========================================"\n\
{% if jupyter %}echo "ðŸ’¡ Jupyter Lab: jupyter lab --ip 0.0.0.0 --allow-root"\n{% endif %}\
{% if claude_code %}echo "ðŸ’¡ Claude Code: claude"\n{% endif %}\
exec "$@"' > /entrypoint.sh \
    && chmod +x /entrypoint.sh

ENTRYPOINT ["/entrypoint.sh"]
CMD ["/bin/bash"]