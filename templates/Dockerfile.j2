# 自動生成されたDockerfile - {{ timestamp }}
FROM {{ base.image }}:{{ base.tag }}

# ────────────── 基本 ENV ──────────────
ENV BNB_CUDA_VERSION={{ base.cuda_version | replace(".", "") }}
ENV PYTHONUNBUFFERED=1
ENV CUDA_HOME=/usr/local/cuda
ENV PATH=${CUDA_HOME}/bin:${PATH}
ENV LD_LIBRARY_PATH=${CUDA_HOME}/lib64:${LD_LIBRARY_PATH}

# ────────────── OS パッケージ ──────────────
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl ca-certificates git build-essential cmake ninja-build wget \
{% if claude_code.install %}
    # Node.js と npm（Claude Code 用）
    && curl -fsSL https://deb.nodesource.com/setup_20.x | bash - \
    && apt-get install -y nodejs \
{% endif %}
    && rm -rf /var/lib/apt/lists/*

# ────────────── PyTorch ──────────────
{% if deep_learning.pytorch.source == "pip" %}
RUN pip uninstall -y torch torchvision torchaudio || true
RUN {{ pytorch_install_command }}
{% endif %}

# ────────────── bitsandbytes（手動ビルド） ──────────────
RUN git clone --depth 1 https://github.com/bitsandbytes-foundation/bitsandbytes.git && \
    cd bitsandbytes && \
    export BNB_CUDA_VERSION={{ base.cuda_version | replace(".", "") }} && \
    cmake -DCOMPUTE_BACKEND=cuda -S . && \
    make -j$(nproc) && \
    pip install -e . && \
    cd .. && rm -rf bitsandbytes

{% if deep_learning.attention.xformers %}
# ────────────── xformers ──────────────
RUN pip install -U "xformers{% if deep_learning.attention.xformers_version %}=={{ deep_learning.attention.xformers_version }}{% endif %}" \
    --index-url https://download.pytorch.org/whl/{{ cuda_short }} --no-deps
{% endif %}

{% if deep_learning.attention.flash_attention %}
# ────────────── Flash-Attention ──────────────
RUN pip install ninja && \
    pip install flash-attn --no-build-isolation
{% endif %}

{% if deep_learning.attention.triton %}
# ────────────── Triton ──────────────
RUN pip install -U --index-url https://aiinfra.pkgs.visualstudio.com/PublicPackages/_packaging/Triton-Nightly/pypi/simple/ triton-nightly
{% endif %}

{% if libraries_flat %}
# ────────────── 追加 Python ライブラリ ──────────────
RUN pip install --no-cache-dir \
{%- for lib in libraries_flat %}
{%- if lib.source is defined %}
    {{ lib.source }}{% if not loop.last %} && \{% endif %}
{%- elif lib.install is defined and lib.install %}
    {{ lib.name }}{% if lib.extra is defined %}[{{ lib.extra }}]{% endif %}{% if not loop.last %} \{% endif %}
{%- elif lib.version is defined and lib.version %}
    {{ lib.name }}{{ lib.version }}{% if not loop.last %} \{% endif %}
{%- else %}
    {{ lib.name }}{% if not loop.last %} \{% endif %}
{%- endif %}
{% endfor %}
    && echo "Python libraries installed successfully"
{% endif %}

{% if claude_code.install %}
# ────────────── Claude Code ──────────────
RUN npm install -g @anthropic-ai/claude-code
{% endif %}

# ────────────── 分散設定（必要に応じて） ──────────────
ENV MASTER_ADDR=localhost
ENV MASTER_PORT=29500
ENV WORLD_SIZE={{ gpu.count }}

# ────────────── カスタム ENV ──────────────
{% for env_var in env_vars %}
ENV {{ env_var.name }}={{ env_var.value }}
{% endfor %}

WORKDIR {{ workspace.directory }}

# ────────────── 動作チェック ──────────────
RUN python - <<'PY'
import torch, importlib
print("CUDA available:", torch.cuda.is_available())
print("GPU count:", torch.cuda.device_count())
for mod in ("flash_attn","transformers","vllm","lightllm","torchtune","unsloth"):
    try:
        m=importlib.import_module(mod)
        print(mod, getattr(m,"__version__", "imported"))
    except ImportError:
        pass
PY

RUN python - <<'PY'
import torch
[print(f"GPU {i}: {torch.cuda.get_device_name(i)}") for i in range(torch.cuda.device_count())]
PY