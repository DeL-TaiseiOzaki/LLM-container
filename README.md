# ğŸš€ Simple LLM Docker Builder

LLMé–‹ç™ºç’°å¢ƒã‚’æ•°åˆ†ã§æ§‹ç¯‰ã§ãã‚‹ã€ã‚·ãƒ³ãƒ—ãƒ«ã§å®Ÿç”¨çš„ãªDockerãƒ“ãƒ«ãƒ€ãƒ¼

## âœ¨ ç‰¹å¾´

- **ğŸ¯ ã‚·ãƒ³ãƒ—ãƒ«**: YAMLãƒ•ã‚¡ã‚¤ãƒ«1ã¤ã§è¨­å®šå®Œäº†
- **âš¡ é«˜é€Ÿ**: uvãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã«ã‚ˆã‚‹é«˜é€Ÿã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«  
- **ğŸ”§ æŸ”è»Ÿ**: å¿…è¦ãªãƒ„ãƒ¼ãƒ«ã ã‘ã‚’é¸æŠå¯èƒ½
- **ğŸ¤– Claude Codeå¯¾å¿œ**: AIé–‹ç™ºæ”¯æ´ãƒ„ãƒ¼ãƒ«çµ±åˆ
- **ğŸ“Š MLOpså¯¾å¿œ**: Weights & Biasesã€MLflowçµ±åˆå¯èƒ½

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆï¼ˆ3åˆ†ã§ç’°å¢ƒæ§‹ç¯‰ï¼‰

```bash
# 1. ãƒªãƒã‚¸ãƒˆãƒªã‚’ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/yourusername/simple-llm-docker.git
cd simple-llm-docker

# 2. åˆæœŸè¨­å®šï¼ˆCUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³è‡ªå‹•æ¤œå‡ºï¼‰
make init

# 3. å¿…è¦ã«å¿œã˜ã¦config.yamlã‚’ç·¨é›†

# 4. ãƒ“ãƒ«ãƒ‰ï¼†èµ·å‹•
make all

# 5. ã‚³ãƒ³ãƒ†ãƒŠã«æ¥ç¶š
make exec
```

ã“ã‚Œã ã‘ã§ã€PyTorch + Transformers + vLLMç’°å¢ƒãŒç«‹ã¡ä¸ŠãŒã‚Šã¾ã™ï¼

## ğŸ“¦ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã‚‹ã‚‚ã®

### åŸºæœ¬ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆå¸¸ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼‰
- PyTorchï¼ˆCUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«æœ€é©åŒ–ï¼‰
- Transformers
- NumPy, Pandas, Matplotlib
- Accelerate, Datasets
- Hugging Face Hub

### ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆconfig.yamlã§é¸æŠï¼‰

| ã‚«ãƒ†ã‚´ãƒª | ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ | èª¬æ˜ | ç”¨é€” |
|---------|----------|------|-----|
| **æ¨è«–** | vLLM | PagedAttentioné«˜é€Ÿæ¨è«– | æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤ |
| **å­¦ç¿’** | TRL | å¼·åŒ–å­¦ç¿’ï¼ˆRLHF/DPOï¼‰ | ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆ |
|  | Unsloth | 2å€é€Ÿãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚° | QLoRAå­¦ç¿’ |
|  | DeepSpeed | åˆ†æ•£å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ | å¤§è¦æ¨¡å­¦ç¿’ |
|  | Flash Attention 2 | ãƒ¡ãƒ¢ãƒªåŠ¹ç‡æ”¹å–„ | é•·æ–‡å‡¦ç† |
| **API** | OpenAI | GPT-4/GPT-3.5é€£æº | APIçµ±åˆ |
|  | LiteLLM | çµ±ä¸€APIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ | ãƒãƒ«ãƒLLM |
|  | LangChain | LLMã‚¢ãƒ—ãƒªé–‹ç™º | RAG/Agent |
| **MLOps** | Weights & Biases | å®Ÿé¨“ç®¡ç†ãƒ»è¿½è·¡ | å®Ÿé¨“è¨˜éŒ² |
|  | MLflow | ãƒ¢ãƒ‡ãƒ«ç®¡ç† | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç† |
| **é–‹ç™º** | Claude Code | AIé–‹ç™ºæ”¯æ´ | ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ |
|  | Jupyter Lab | ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ç’°å¢ƒ | å®Ÿé¨“ãƒ»åˆ†æ |

## ğŸ“ ä½¿ã„æ–¹

### åŸºæœ¬ã‚³ãƒãƒ³ãƒ‰

```bash
make init      # åˆæœŸè¨­å®šï¼ˆåˆå›ã®ã¿ï¼‰
make build     # ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰
make run       # ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•
make exec      # ã‚³ãƒ³ãƒ†ãƒŠæ¥ç¶š
make stop      # ã‚³ãƒ³ãƒ†ãƒŠåœæ­¢
make logs      # ãƒ­ã‚°è¡¨ç¤º
make clean     # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
```

### config.yaml ã®ç·¨é›†

```yaml
# åŸºæœ¬è¨­å®š
cuda_version: "12.1"        # ã‚ãªãŸã®GPUã«åˆã‚ã›ã¦å¤‰æ›´
python_version: "3.11"      # 3.9ã€œ3.12ã‹ã‚‰é¸æŠ

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸é¸æŠï¼ˆtrue/falseã§åˆ‡ã‚Šæ›¿ãˆï¼‰
packages:
  vllm: true               # é«˜é€Ÿæ¨è«–ãŒå¿…è¦ãªã‚‰
  flash_attention2: true   # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ã‚’é‡è¦–ã™ã‚‹ãªã‚‰
  openai: true            # OpenAI APIä½¿ã†ãªã‚‰
  wandb: false            # å®Ÿé¨“ç®¡ç†ãŒå¿…è¦ãªã‚‰
  # ... ä»–ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚‚åŒæ§˜ã«
```

### æ§‹æˆä¾‹

**æœ€å°æ§‹æˆï¼ˆæ¨è«–ã®ã¿ï¼‰**
```yaml
packages:
  vllm: true
  openai: true
```

**ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ§‹æˆ**
```yaml
packages:
  trl: true
  unsloth: true
  flash_attention2: true
  wandb: true
```

**ãƒ•ãƒ«ã‚¹ã‚¿ãƒƒã‚¯é–‹ç™º**
```yaml
packages:
  vllm: true
  langchain: true
  openai: true
  mlflow: true
```

## ğŸ”§ ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º

### ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸ã®å¤‰æ›´

`templates/Dockerfile.j2` ã®æœ€åˆã®è¡Œã‚’ç·¨é›†ã™ã‚‹ã“ã¨ã§ã€ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’è‡ªç”±ã«å¤‰æ›´ã§ãã¾ã™ï¼š

```dockerfile

# ä¾‹1: PyTorchå…¬å¼ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ç”¨
FROM pytorch/pytorch:2.5.1-cuda12.1-cudnn9-runtime

# ä¾‹2: nvidiaå…¬å¼ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ä½¿ç”¨
FROM nvidia/cuda:12.8.0-cudnn-devel-ubuntu22.04

# ä¾‹3: CPUå°‚ç”¨ï¼ˆGPUä¸è¦ã®å ´åˆï¼‰
FROM ubuntu:22.04
```

**æ³¨æ„äº‹é …**ï¼š
- CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ `config.yaml` ã® `cuda_version` ã§åˆ¶å¾¡ã•ã‚Œã¾ã™
- Ubuntu 22.04ãƒ™ãƒ¼ã‚¹ã‚’æ¨å¥¨ï¼ˆä¾å­˜é–¢ä¿‚ã®äº’æ›æ€§ï¼‰
- å¤‰æ›´å¾Œã¯ `make build` ã§å†ãƒ“ãƒ«ãƒ‰ãŒå¿…è¦ã§ã™

### ç’°å¢ƒå¤‰æ•°ã®è¨­å®š

`docker-compose.yml` ã§ç’°å¢ƒå¤‰æ•°ã‚’ç®¡ç†ï¼š

```yaml
environment:
  - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
  - OPENAI_API_KEY=${OPENAI_API_KEY}
  - HUGGING_FACE_HUB_TOKEN=${HF_TOKEN}
```

`.env` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦è‡ªå‹•èª­ã¿è¾¼ã¿ï¼š
```bash
echo "OPENAI_API_KEY=sk-xxx" >> .env
echo "HF_TOKEN=hf_xxx" >> .env
```

## ğŸ¯ CUDA-PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³å¯¾å¿œè¡¨

| CUDA | æ¨å¥¨PyTorch | ãã®ä»–åˆ©ç”¨å¯èƒ½ | æ¨å¥¨GPU |
|------|------------|-------------|---------|
| **11.8** | 2.5.1 | 2.3.1ã€œ2.7.0 | å¹…åºƒã„äº’æ›æ€§ |
| **12.1** | 2.5.1 | 2.3.1ã€œ2.5.1 | RTX 30xx/A100 |
| **12.4** | 2.6.0 | 2.4.1ã€œ2.6.0 | RTX 40xx |
| **12.8** | 2.7.0 | 2.7.0ã®ã¿ | H100/H200 |

CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ç¢ºèªï¼š
```bash
nvidia-smi  # "CUDA Version: XX.X" ã‚’ç¢ºèª
```

## ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºç­–

**Q: CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒã‚ã‹ã‚‰ãªã„**
```bash
nvidia-smi | grep "CUDA Version"
# ã¾ãŸã¯
make init  # è‡ªå‹•æ¤œå‡ºã•ã‚Œã¾ã™
```

**Q: ãƒ¡ãƒ¢ãƒªä¸è¶³ã‚¨ãƒ©ãƒ¼ï¼ˆFlash Attentionãƒ“ãƒ«ãƒ‰æ™‚ï¼‰**
```yaml
# config.yaml ã§ç„¡åŠ¹åŒ–
packages:
  flash_attention2: false
```

**Q: æ—¢å­˜ã®ã‚³ãƒ³ãƒ†ãƒŠã¨ç«¶åˆã™ã‚‹**
```bash
make clean  # æ—¢å­˜ç’°å¢ƒã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
make all    # å†æ§‹ç¯‰
```

**Q: GPUãŒèªè­˜ã•ã‚Œãªã„**
```bash
# Dockerå†…ã§ç¢ºèª
docker exec -it llm-dev nvidia-smi

# NVIDIA Container Toolkitã®å†ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›®å®‰

| æ§‹æˆ | ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚µã‚¤ã‚º | ãƒ“ãƒ«ãƒ‰æ™‚é–“ | ç”¨é€” |
|-----|--------------|-----------|-----|
| æœ€å°æ§‹æˆ | ç´„8GB | 5-10åˆ† | æ¨è«–ã®ã¿ |
| æ¨™æº–æ§‹æˆ | ç´„12GB | 10-15åˆ† | é–‹ç™ºãƒ»å®Ÿé¨“ |
| ãƒ•ãƒ«æ§‹æˆ | ç´„18GB | 15-20åˆ† | å…¨æ©Ÿèƒ½ |

## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
simple-llm-docker/
â”œâ”€â”€ build.py               # ãƒ“ãƒ«ãƒ‰ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ config.yaml           # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ docker-compose.yaml    # Docker Composeè¨­å®š
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ Dockerfile.j2     # Dockerfileãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
â”œâ”€â”€ workspace/            # ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆè‡ªå‹•ä½œæˆï¼‰
â”œâ”€â”€ Makefile             # ä¾¿åˆ©ã‚³ãƒãƒ³ãƒ‰
â”œâ”€â”€ requirements.txt     # Pythonä¾å­˜
â””â”€â”€ README.md           # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
```

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

Apache License 2.0
