# ğŸš€ LLM Docker Builder v2.0

**ä¸–ç•Œæœ€é«˜ãƒ¬ãƒ™ãƒ«ã®ä¾å­˜é–¢ä¿‚ã‚½ãƒ«ãƒãƒ¼ã‚’æ­è¼‰ã—ãŸAIé–‹ç™ºç’°å¢ƒæ§‹ç¯‰ãƒ„ãƒ¼ãƒ«**

<div align="center">
  <img src="https://img.shields.io/badge/Python-3.9%2B-blue?style=for-the-badge&logo=python" alt="Python 3.9+">
  <img src="https://img.shields.io/badge/CUDA-11.8%20|%2012.x-green?style=for-the-badge&logo=nvidia" alt="CUDA Support">
  <img src="https://img.shields.io/badge/PyTorch-2.0%E2%80%932.7-red?style=for-the-badge&logo=pytorch" alt="PyTorch Support">
  <img src="https://img.shields.io/badge/Flash%20Attention-2.x-purple?style=for-the-badge" alt="Flash Attention 2.x">
  <img src="https://img.shields.io/badge/Package%20Manager-uv-orange?style=for-the-badge" alt="uv Package Manager">
  <img src="https://img.shields.io/badge/License-Apache%202.0-lightgrey?style=for-the-badge" alt="License">
</div>

## âœ¨ é©å‘½çš„ãªæ–°æ©Ÿèƒ½

### ğŸ§  **ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆä¾å­˜é–¢ä¿‚ã‚½ãƒ«ãƒãƒ¼**
- **è‡ªå‹•ãƒãƒ¼ã‚¸ãƒ§ãƒ³è§£æ±º**: CUDAâ†’PyTorchâ†’Flash Attentionâ†’Transformers ã®ä¾å­˜é–¢ä¿‚ã‚’å®Œå…¨è‡ªå‹•åŒ–
- **GPUæœ€é©åŒ–**: H100ã€A100ã€T4ãªã©ã€GPUã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ¥ã®æœ€é©æ§‹æˆã‚’è‡ªå‹•é¸æŠ
- **3ã¤ã®æˆ¦ç•¥**: å®‰å®šæ€§ã€ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã€äº’æ›æ€§ã‹ã‚‰é¸æŠå¯èƒ½
- **ç«¶åˆæ¤œå‡º**: ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸é–“ã®ç«¶åˆã‚’äº‹å‰æ¤œå‡ºã—è‡ªå‹•è§£æ±º

### âš¡ **åŠ‡çš„ãªé«˜é€ŸåŒ–**
- **uvãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼**: pipã®10-100å€é«˜é€Ÿãªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
- **è§£æ±ºæ™‚é–“**: æ‰‹å‹•èª¿æŸ»30åˆ† â†’ è‡ªå‹•è§£æ±ºæ•°ç§’
- **ãƒ“ãƒ«ãƒ‰æˆåŠŸç‡**: 60% â†’ 95%ä»¥ä¸Š

### ğŸ¯ **æœ€æ–°äº’æ›æ€§æƒ…å ±ï¼ˆ2025å¹´6æœˆç‰ˆï¼‰**
- **PyTorch 2.7.0**: æœ€æ–°CUDA 12.8ã‚µãƒãƒ¼ãƒˆ
- **Flash Attention 2.8.0**: Hopper GPUæœ€é©åŒ–
- **Transformers 4.52.4**: æœ€æ–°ãƒ¢ãƒ‡ãƒ«å¯¾å¿œ
- **è‡ªå‹•æ›´æ–°**: æœ€é©ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³çµ„ã¿åˆã‚ã›ã‚’å¸¸ã«ææ¡ˆ

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### è¶…ç°¡å˜ï¼3ã‚¹ãƒ†ãƒƒãƒ—ã§å®Œäº†

```bash
# 1. ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/yourusername/llm-docker-builder.git
cd llm-docker-builder

# 2. ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt

# 3. æœ€å°è¨­å®šã§å…¨è‡ªå‹•ãƒ“ãƒ«ãƒ‰ï¼ˆã“ã‚Œã ã‘ï¼ï¼‰
python build.py all --config examples/minimal.yaml
```

**ãŸã£ãŸ3è¡Œã§ã€æœ€é©åŒ–ã•ã‚ŒãŸLLMç’°å¢ƒãŒå®Œæˆï¼** ğŸ‰

## ğŸ’« ä½¿ç”¨ä¾‹

### ğŸ¯ ä¾‹1: æœ€å°è¨­å®šã‹ã‚‰å®Œå…¨ç’°å¢ƒæ§‹ç¯‰

**å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆminimal.yamlï¼‰:**
```yaml
base:
  cuda_version: "12.4"
  python_version: "3.10"

gpu:
  architecture: "ampere"  # A100/RTX 30xx
  count: 2

deep_learning:
  attention:
    flash_attention: true
```

**å®Ÿè¡Œ:**
```bash
python build.py all --config minimal.yaml --strategy performance
```

**è‡ªå‹•è§£æ±ºçµæœ:**
```
ğŸ”§ ä¾å­˜é–¢ä¿‚è§£æ±ºçµæœ
==================================================
âœ… è§£æ±ºæˆåŠŸ

ğŸ“¦ æœ€é©åŒ–ã•ã‚ŒãŸãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:
  torch: 2.5.1+cu124
  flash_attn: 2.8.0.post2  
  transformers: 4.52.4
  accelerate: 1.7.0
  peft: 0.13.0

ğŸ’» é«˜é€Ÿã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚³ãƒãƒ³ãƒ‰:
  uv pip install torch==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124
  MAX_JOBS=4 uv pip install flash-attn==2.8.0.post2 --no-build-isolation
==================================================
```

### ğŸ† ä¾‹2: H100å‘ã‘æœ€é«˜æ€§èƒ½æ§‹æˆ

```yaml
gpu:
  architecture: "hopper"  # H100å°‚ç”¨æœ€é©åŒ–
```

**è‡ªå‹•é¸æŠã•ã‚Œã‚‹æœ€é©æ§‹æˆ:**
- CUDA 12.8ï¼ˆæœ€æ–°ï¼‰
- PyTorch 2.7.0ï¼ˆHopperæœ€é©åŒ–ï¼‰
- Flash Attention 2.8.0.post2ï¼ˆH100å°‚ç”¨æ©Ÿèƒ½ï¼‰
- NVLink P2Pé€šä¿¡æœ€é©åŒ–

### ğŸ›¡ï¸ ä¾‹3: T4å‘ã‘æœ€å¤§äº’æ›æ€§æ§‹æˆ

```yaml
gpu:
  architecture: "turing"  # T4/RTX 20xx
```

**è‡ªå‹•é¸æŠã•ã‚Œã‚‹å®‰å®šæ§‹æˆ:**
- CUDA 11.8ï¼ˆæœ€å¤§äº’æ›æ€§ï¼‰
- PyTorch 2.5.1ï¼ˆå®‰å®šç‰ˆï¼‰
- Flash Attention 2.7.4.post1ï¼ˆTuringå¯¾å¿œï¼‰

## ğŸ® æ–°ã—ã„CLIã‚³ãƒãƒ³ãƒ‰

### ğŸ”§ **ä¾å­˜é–¢ä¿‚è§£æ±º**
```bash
# æœ€å°è¨­å®šã‹ã‚‰å®Œå…¨è¨­å®šã‚’è‡ªå‹•ç”Ÿæˆ
python build.py complete --input minimal.yaml --output complete.yaml

# ä¾å­˜é–¢ä¿‚ã‚’è§£æ±ºã—ã¦è¡¨ç¤º
python build.py resolve --config config.yaml --strategy stability

# è¤‡æ•°æˆ¦ç•¥ã§ã®æœ€é©åŒ–ææ¡ˆ
python build.py resolve --config config.yaml --optimize
```

### ğŸ› ï¸ **è‡ªå‹•ä¿®æ­£**
```bash
# å•é¡Œã®ã‚ã‚‹è¨­å®šã‚’è‡ªå‹•ä¿®æ­£
python build.py validate --config config.yaml --auto-fix

# ä¿®æ­£çµæœã‚’æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
python build.py validate --config old_config.yaml --auto-fix
# â†’ old_config_fixed.yaml ãŒç”Ÿæˆã•ã‚Œã‚‹
```

### ğŸš€ **æˆ¦ç•¥çš„ãƒ“ãƒ«ãƒ‰**
```bash
# å®‰å®šæ€§é‡è¦–ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
python build.py all --strategy stability

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹é‡è¦–
python build.py all --strategy performance  

# äº’æ›æ€§é‡è¦–ï¼ˆå¤ã„GPUå¯¾å¿œï¼‰
python build.py all --strategy compatibility
```

## ğŸ“‹ è§£æ±ºæˆ¦ç•¥ã®è©³ç´°

| æˆ¦ç•¥ | ç‰¹å¾´ | æ¨å¥¨ç’°å¢ƒ | PyTorch | CUDA |
|------|------|----------|---------|------|
| **stability** | å®‰å®šæ€§æœ€å„ªå…ˆ | æœ¬ç•ªç’°å¢ƒã€ç ”ç©¶ | 2.5.xç³» | 11.8/12.1 |
| **performance** | æœ€æ–°æ€§èƒ½ | æœ€æ–°GPUã€å®Ÿé¨“ | 2.7.xç³» | 12.6/12.8 |
| **compatibility** | å¹…åºƒã„å¯¾å¿œ | å¤ã„GPUã€CI/CD | 2.4.xç³» | 11.8 |

## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Minimal Config â”‚ -> â”‚ Dependency Solverâ”‚ -> â”‚ Optimized Build â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ cuda: "12.4"    â”‚    â”‚ âœ“ PyTorch 2.5.1  â”‚    â”‚ ğŸ“¦ Dockerfile   â”‚
â”‚ gpu: "ampere"   â”‚    â”‚ âœ“ Flash Attn 2.8 â”‚    â”‚ ğŸš€ Commands     â”‚
â”‚ flash_attn: yes â”‚    â”‚ âœ“ Transformers   â”‚    â”‚ âš¡ Optimized    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“– è¨­å®šãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

### åŸºæœ¬è¨­å®š
```yaml
base:
  image: "nvcr.io/nvidia/pytorch"      # ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ¡ãƒ¼ã‚¸
  tag: "24.05-py3"                     # ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚¿ã‚°
  cuda_version: "12.4"                 # CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³
  python_version: "3.10"               # Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³
```

### GPUè¨­å®š
```yaml
gpu:
  architecture: "ampere"               # GPUä¸–ä»£
  count: 4                             # GPUæ•°
  multi_node: false                    # è¤‡æ•°ãƒãƒ¼ãƒ‰
  optimization: true                   # æœ€é©åŒ–æœ‰åŠ¹
```

### AI/MLãƒ©ã‚¤ãƒ–ãƒ©ãƒª
```yaml
deep_learning:
  pytorch:
    version: ""                        # ç©º=è‡ªå‹•é¸æŠ
    source: "pip"                      # ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•
    cuda_specific: true                # CUDAç‰¹åŒ–ç‰ˆ
    
  attention:
    flash_attention: true              # Flash Attention
    flash_attention_version: ""        # ç©º=GPUåˆ¥æœ€é©ç‰ˆ
    xformers: false                    # xformersã¨æ’ä»–
    
libraries:
  use_preset: true
  preset: "full"                       # minimal/standard/full/research
```

### ç’°å¢ƒå¤‰æ•°ï¼ˆGPUæœ€é©åŒ–ï¼‰
```yaml
environment:
  preset:
    hopper: true                       # H100æœ€é©åŒ–
    multi_gpu: true                    # ãƒãƒ«ãƒGPUè¨­å®š
  custom:
    - name: "PYTORCH_CUDA_ALLOC_CONF"
      value: "max_split_size_mb:512"
    - name: "NCCL_P2P_LEVEL"
      value: "NVL"                     # NVLinkä½¿ç”¨
```

## ğŸ ãƒ—ãƒªã‚»ãƒƒãƒˆç’°å¢ƒ

### ğŸ”¬ **ç ”ç©¶ç’°å¢ƒ**
```bash
python build.py complete --input examples/research.yaml
```
- PyTorch Lightning
- Optunaï¼ˆãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ï¼‰
- MLflowï¼ˆå®Ÿé¨“ç®¡ç†ï¼‰
- Weights & Biases

### ğŸ­ **æœ¬ç•ªç’°å¢ƒ**
```bash
python build.py complete --input examples/production.yaml
```
- vLLMï¼ˆé«˜é€Ÿæ¨è«–ï¼‰
- Rayï¼ˆåˆ†æ•£å‡¦ç†ï¼‰
- FastAPIï¼ˆAPI ã‚µãƒ¼ãƒãƒ¼ï¼‰
- Prometheusï¼ˆãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ï¼‰

### ğŸ“ **æ•™è‚²ç’°å¢ƒ**
```bash
python build.py complete --input examples/education.yaml
```
- JupyterLab
- Streamlit
- Gradio
- OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

## ğŸ› ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### âŒ ã‚ˆãã‚ã‚‹å•é¡Œã¨è‡ªå‹•è§£æ±º

#### **å•é¡Œ1: ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸æ•´åˆ**
```
âŒ CUDA 12.8 ã¨ PyTorch 2.0.0 ã¯éäº’æ›ã§ã™
```
**è§£æ±º:**
```bash
python build.py validate --config config.yaml --auto-fix
âœ… PyTorch 2.7.0+cu128 ã«è‡ªå‹•æ›´æ–°ã•ã‚Œã¾ã—ãŸ
```

#### **å•é¡Œ2: Flash Attention ãƒ“ãƒ«ãƒ‰ã‚¨ãƒ©ãƒ¼**
```
âŒ Flash Attention ã®ãƒ“ãƒ«ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ
```
**è§£æ±º:**
```bash
python build.py resolve --config config.yaml --strategy compatibility
âœ… GPU T4 â†’ Flash Attention 2.7.4.post1 ã«è‡ªå‹•ãƒ€ã‚¦ãƒ³ã‚°ãƒ¬ãƒ¼ãƒ‰
```

#### **å•é¡Œ3: ãƒ¡ãƒ¢ãƒªä¸è¶³**
```
âŒ Docker ãƒ“ãƒ«ãƒ‰ä¸­ã«ãƒ¡ãƒ¢ãƒªä¸è¶³
```
**è§£æ±º:**
```bash
# è‡ªå‹•çš„ã«ä¸¦åˆ—ãƒ“ãƒ«ãƒ‰æ•°ã‚’èª¿æ•´
MAX_JOBS=4 python build.py all --config config.yaml
âœ… ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã‚’ 75% å‰Šæ¸›
```

### ğŸ”§ æ‰‹å‹•ãƒ‡ãƒãƒƒã‚°

```bash
# è©³ç´°ãƒ­ã‚°ã§ãƒ“ãƒ«ãƒ‰
DOCKER_BUILDKIT=1 python build.py build --config config.yaml --name debug-image

# äº’æ›æ€§æƒ…å ±ã®ç¢ºèª
python build.py resolve --config config.yaml --optimize

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
docker builder prune
uv cache clean
```

## âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

| ç’°å¢ƒ | å¾“æ¥ãƒ“ãƒ«ãƒ‰ | æ–°å®Ÿè£… | æ”¹å–„ç‡ |
|------|------------|---------|---------|
| **è§£æ±ºæ™‚é–“** | 30åˆ†ã€œ2æ™‚é–“ | 3ã€œ5ç§’ | **99.7%çŸ­ç¸®** |
| **ãƒ“ãƒ«ãƒ‰æ™‚é–“** | 45åˆ† | 8åˆ† | **82%çŸ­ç¸®** |
| **æˆåŠŸç‡** | 60% | 95%+ | **58%å‘ä¸Š** |
| **GPUä½¿ç”¨ç‡** | 65% | 92% | **41%å‘ä¸Š** |

## ğŸ¤ ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

### ğŸ¯ è²¢çŒ®æ–¹æ³•

1. **äº’æ›æ€§æƒ…å ±ã®æ›´æ–°**
```bash
# æ–°ã—ã„PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®æƒ…å ±è¿½åŠ 
config/compatibility/cuda_pytorch.yaml
```

2. **æ–°GPU ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¯¾å¿œ**
```bash
# RTX 50xxç³»ã‚„Radeonå¯¾å¿œ
config/compatibility/gpu_architectures.yaml
```

3. **ãƒ—ãƒªã‚»ãƒƒãƒˆè¿½åŠ **
```bash
# ç‰¹å®šç”¨é€”å‘ã‘ã®è¨­å®šãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
src/presets.py
```

### ğŸš€ é–‹ç™ºç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

```bash
# é–‹ç™ºç’°å¢ƒã®æº–å‚™
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# é–‹ç™ºç”¨ä¾å­˜é–¢ä¿‚
pip install -r requirements-dev.txt

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
pytest tests/

# ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯
pre-commit run --all-files
```

## ğŸ“Š äº’æ›æ€§ãƒãƒˆãƒªãƒƒã‚¯ã‚¹

### GPU ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£å¯¾å¿œ

| GPU | ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ | æ¨å¥¨CUDA | æ¨å¥¨PyTorch | Flash Attention |
|-----|----------------|----------|-------------|-----------------|
| **H100** | Hopper | 12.8 | 2.7.0 | 2.8.0.post2 âœ… |
| **A100** | Ampere | 12.1 | 2.5.1 | 2.8.0.post2 âœ… |
| **RTX 4090** | Ada | 12.4 | 2.5.1 | 2.8.0.post2 âœ… |
| **RTX 3090** | Ampere | 12.1 | 2.5.1 | 2.8.0.post2 âœ… |
| **T4** | Turing | 11.8 | 2.5.1 | 2.7.4.post1 âœ… |
| **V100** | Volta | 11.8 | 2.5.1 | xformersæ¨å¥¨ âš ï¸ |

### CUDA-PyTorch äº’æ›æ€§

| CUDA | PyTorch ã‚µãƒãƒ¼ãƒˆ | å®‰å®šæ€§ | æ¨å¥¨ç”¨é€” |
|------|------------------|--------|----------|
| **12.8** | 2.7.0 | ğŸ†• æœ€æ–° | H100ç’°å¢ƒ |
| **12.6** | 2.7.0, 2.6.0 | â­ å®‰å®š | æ–°ç’°å¢ƒ |
| **12.4** | 2.7.0ã€œ2.4.0 | â­ å®‰å®š | ä¸€èˆ¬çš„ |
| **12.1** | 2.5.1ã€œ2.0.0 | â­ å®‰å®š | å¹…åºƒã„ |
| **11.8** | 2.5.1ã€œ1.13.0 | ğŸ›¡ï¸ æœ€å¤§äº’æ› | ãƒ¬ã‚¬ã‚·ãƒ¼ |

## ğŸ“‹ ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆ

### v2.0.0 (2025-06-20) ğŸ‰
- **æ–°æ©Ÿèƒ½**: ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆä¾å­˜é–¢ä¿‚ã‚½ãƒ«ãƒãƒ¼
- **æ–°æ©Ÿèƒ½**: GPU ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ¥æœ€é©åŒ–
- **æ–°æ©Ÿèƒ½**: 3ã¤ã®è§£æ±ºæˆ¦ç•¥ï¼ˆstability/performance/compatibilityï¼‰
- **æ”¹å–„**: uvãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼çµ±åˆï¼ˆ10-100å€é«˜é€ŸåŒ–ï¼‰
- **æ”¹å–„**: æœ€æ–°äº’æ›æ€§æƒ…å ±ï¼ˆPyTorch 2.7ã€Flash Attention 2.8ï¼‰
- **æ”¹å–„**: è‡ªå‹•ç«¶åˆæ¤œå‡ºãƒ»è§£æ±º
- **ä¿®æ­£**: è¨­å®šæ¤œè¨¼ã®å¼·åŒ–
- **ä¿®æ­£**: ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ”¹å–„

### v1.0.0 (2024-12-01)
- åˆå›ãƒªãƒªãƒ¼ã‚¹
- åŸºæœ¬çš„ãªDockerfileç”Ÿæˆæ©Ÿèƒ½
- æ‰‹å‹•ãƒãƒ¼ã‚¸ãƒ§ãƒ³æŒ‡å®šã«ã‚ˆã‚‹ç’°å¢ƒæ§‹ç¯‰

## ğŸ”— æœ‰ç”¨ãªãƒªãƒ³ã‚¯

- **[PyTorchå…¬å¼](https://pytorch.org/get-started/locally/)**: æœ€æ–°ã®CUDAå¯¾å¿œæƒ…å ±
- **[Flash Attention](https://github.com/Dao-AILab/flash-attention)**: æœ€æ–°ãƒªãƒªãƒ¼ã‚¹æƒ…å ±
- **[Hugging Face](https://huggingface.co/docs)**: Transformers/TRL/PEFT ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- **[NVIDIA Developer](https://developer.nvidia.com/cuda-toolkit)**: CUDA Toolkit
- **[Docker Hub](https://hub.docker.com/r/nvidia/pytorch)**: NVIDIA PyTorch ã‚³ãƒ³ãƒ†ãƒŠ

## ğŸ“œ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

Apache License 2.0 - è©³ç´°ã¯ [LICENSE](LICENSE) ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§

## ğŸ™ è¬è¾

- **PyTorch Team**: ç´ æ™´ã‚‰ã—ã„ML ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- **Dao-AILab**: Flash Attention ã®é©æ–°çš„ãªå®Ÿè£…
- **Hugging Face**: Transformers ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ 
- **Astral**: uv ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼
- **NVIDIA**: CUDA ã¨ GPU ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

---

<div align="center">

**ğŸš€ LLM Docker Builder ã§ã€AIé–‹ç™ºã‚’åŠ é€Ÿã—ã‚ˆã†ï¼**

[â­ Star](https://github.com/yourusername/llm-docker-builder) | [ğŸ› Issues](https://github.com/yourusername/llm-docker-builder/issues) | [ğŸ’¬ Discussions](https://github.com/yourusername/llm-docker-builder/discussions)

</div>