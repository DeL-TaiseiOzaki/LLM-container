# Transformers生態系の互換性マップ（2025年6月版）
# 情報源: PyPI + GitHub releases + 調査結果

transformers:
  "4.52.4":
    requires_pytorch: ">=2.1.0"
    requires_python: ">=3.9"
    compatible_cuda: ["11.8", "12.1", "12.4", "12.6", "12.8"]
    status: "latest"
    breaking_changes: ["dropped_python_3.8"]
  "4.51.3":
    requires_pytorch: ">=2.0.0"
    requires_python: ">=3.8"
    compatible_cuda: ["11.8", "12.1", "12.4", "12.6", "12.8"]
    status: "stable"
  "4.42.0":
    requires_pytorch: ">=2.0.0"  # PyTorch要件がここで上昇
    requires_python: ">=3.8"
    compatible_cuda: ["11.8", "12.1", "12.4"]
    status: "legacy"
  "4.41.0":
    requires_pytorch: ">=1.11.0"
    requires_python: ">=3.8"
    compatible_cuda: ["11.1", "11.8", "12.1"]
    status: "legacy"

# TRL (Transformer Reinforcement Learning)
trl:
  "0.18.0":
    requires_transformers: ">=4.40.0"
    requires_pytorch: ">=2.0.0"
    requires_python: ">=3.9"
    compatible_cuda: ["11.8", "12.1", "12.4", "12.6", "12.8"]
    status: "latest"
  "0.17.0":
    requires_transformers: ">=4.40.0"
    requires_pytorch: ">=2.0.0"
    requires_python: ">=3.8"
    compatible_cuda: ["11.8", "12.1", "12.4", "12.6", "12.8"]
    status: "stable"
  "0.10.0":
    requires_transformers: ">=4.34.0"
    requires_pytorch: ">=1.13.1"
    requires_python: ">=3.8"
    status: "legacy"

# Accelerate (分散トレーニング)
accelerate:
  "1.7.0":
    requires_pytorch: ">=2.0.0"
    requires_python: ">=3.8"
    supports_deepspeed: true
    supports_fsdp: true
    supports_fp8: true
    status: "latest"
  "1.6.2":
    requires_pytorch: ">=1.13.0"
    requires_python: ">=3.8"
    supports_deepspeed: true
    supports_fsdp: true
    status: "stable"

# PEFT (Parameter Efficient Fine-Tuning)
peft:
  "0.13.0":
    requires_transformers: ">=4.44.2"
    requires_pytorch: ">=2.0.0"
    requires_python: ">=3.8"
    supports_lora: true
    supports_qlora: true
    supports_adalora: true
    status: "latest"
  "0.10.0":
    requires_transformers: ">=4.40.0"
    requires_pytorch: ">=1.13.1"
    requires_python: ">=3.8"
    status: "stable"

# DeepSpeed
deepspeed:
  "0.16.4":
    requires_pytorch: ">=2.0.0"
    requires_python: ">=3.8"
    cuda_exact_match: true  # PyTorchとCUDAバージョンの厳密一致が必要
    supports_zero1: true
    supports_zero2: true
    supports_zero3: true
    supports_zero_infinity: true
    status: "latest"
  "0.15.4":
    requires_pytorch: ">=1.13.0"
    requires_python: ">=3.7"
    cuda_exact_match: true
    status: "stable"

# xFormers
xformers:
  "0.0.30":
    pytorch_coupling: "tight"  # PyTorchバージョンと密結合
    compatible_pytorch: ["2.7.0"]
    compatible_cuda: ["12.6", "12.8"]
    status: "latest"
  "0.0.29.post2":
    compatible_pytorch: ["2.5.1", "2.6.0"]
    compatible_cuda: ["11.8", "12.1", "12.4"]
    status: "stable"
  "0.0.28":
    compatible_pytorch: ["2.4.0", "2.4.1"]
    compatible_cuda: ["11.8", "12.1"]
    status: "legacy"

# 依存関係解決の優先順位
resolution_priority:
  primary_constraints:
    - "python_version"
    - "cuda_version"
    - "pytorch_version"
  secondary_constraints:
    - "transformers_version"
    - "flash_attention_support"
  optional_constraints:
    - "trl_version"
    - "deepspeed_version"
    - "xformers_version"

# 既知の競合関係
conflicts:
  - packages: ["flash_attention", "xformers"]
    reason: "memory_attention_conflict"
    resolution: "prefer_flash_attention"
  - packages: ["deepspeed", "pytorch_lightning"]
    reason: "distributed_backend_conflict"
    resolution: "configure_separately"