import os
import sys
import yaml
import argparse
import subprocess
from datetime import datetime
from jinja2 import Template

# CUDA-PyTorchå¯¾å¿œè¡¨ï¼ˆ2025å¹´1æœˆæœ€æ–°ï¼‰
CUDA_PYTORCH = {
    "11.8": {
        "pytorch_versions": ["2.7.0", "2.6.0", "2.5.1", "2.4.1", "2.3.1"],
        "default": "2.5.1",  # å®‰å®šç‰ˆ
        "index_url": "https://download.pytorch.org/whl/cu118"
    },
    "12.1": {
        "pytorch_versions": ["2.5.1", "2.4.1", "2.3.1"],
        "default": "2.5.1",
        "index_url": "https://download.pytorch.org/whl/cu121"
    },
    "12.4": {
        "pytorch_versions": ["2.6.0", "2.5.1", "2.4.1"],
        "default": "2.6.0",
        "index_url": "https://download.pytorch.org/whl/cu124"
    },
    "12.6": {
        "pytorch_versions": ["2.7.0", "2.6.0"],
        "default": "2.7.0",
        "index_url": "https://download.pytorch.org/whl/cu126"
    },
    "12.8": {
        "pytorch_versions": ["2.7.0"],
        "default": "2.7.0",
        "index_url": "https://download.pytorch.org/whl/cu128"
    }
}

# ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸èª¬æ˜
PACKAGE_INFO = {
    "vllm": "é«˜é€Ÿæ¨è«–ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆPagedAttentionï¼‰",
    "trl": "å¼·åŒ–å­¦ç¿’ï¼ˆRLHF/DPOï¼‰",
    "unsloth": "é«˜é€Ÿãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆ2xé«˜é€Ÿï¼‰",
    "deepspeed": "åˆ†æ•£å­¦ç¿’ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯",
    "flash_attention2": "Flash Attention 2ï¼ˆãƒ¡ãƒ¢ãƒªåŠ¹ç‡ï¼‰",
    "openai": "OpenAI API ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ",
    "litellm": "çµ±ä¸€LLM APIã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹",
    "langchain": "LLMã‚¢ãƒ—ãƒªé–‹ç™ºãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯",
    "wandb": "å®Ÿé¨“ç®¡ç†ãƒ»ãƒ¢ãƒ‡ãƒ«è¿½è·¡",
    "mlflow": "MLOpsãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ "
}

def get_nvidia_cuda_version():
    """ãƒ›ã‚¹ãƒˆãƒã‚·ãƒ³ã®CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å–å¾—"""
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            for line in result.stdout.split('\n'):
                if 'CUDA Version:' in line:
                    version = line.split('CUDA Version:')[1].strip().split()[0]
                    major_minor = '.'.join(version.split('.')[:2])
                    return major_minor
    except:
        pass
    return None

def init_config():
    """åˆæœŸè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆ"""
    host_cuda = get_nvidia_cuda_version()
    
    if host_cuda:
        print(f"âœ… ãƒ›ã‚¹ãƒˆã®CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’æ¤œå‡º: {host_cuda}")
        cuda_version = host_cuda
    else:
        print("âš ï¸  CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è‡ªå‹•æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸ")
        cuda_version = "12.1"  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    
    config = {
        'cuda_version': cuda_version,
        'python_version': '3.11',
        'transformers_version': '4.56.0',
        'packages': {
            'vllm': True,
            'trl': False,
            'unsloth': False,
            'deepspeed': False,
            'flash_attention2': True,
            'openai': True,
            'litellm': False,
            'langchain': False,
            'wandb': False,
            'mlflow': False
        },
        'claude_code': True,
        'jupyter': True,
        'container_name': 'llm-dev',
        'mount_path': '/workspace'
    }
    
    with open('config.yaml', 'w') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    print("âœ… config.yaml ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
    print("\nğŸ“ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print("  1. config.yaml ã‚’ç·¨é›†ã—ã¦å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’é¸æŠ")
    print("  2. make build ã§ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰")
    print("  3. make run ã§ã‚³ãƒ³ãƒ†ãƒŠã‚’èµ·å‹•")

def load_config(config_path):
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def validate_config(config):
    """è¨­å®šã‚’æ¤œè¨¼"""
    errors = []
    
    # CUDA ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
    if config['cuda_version'] not in CUDA_PYTORCH:
        errors.append(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³: {config['cuda_version']}")
        errors.append(f"åˆ©ç”¨å¯èƒ½: {', '.join(sorted(CUDA_PYTORCH.keys()))}")
    
    # PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if 'pytorch_version' in config:
        cuda_info = CUDA_PYTORCH.get(config['cuda_version'], {})
        if config['pytorch_version'] not in cuda_info.get('pytorch_versions', []):
            errors.append(f"CUDA {config['cuda_version']}ã§ã¯ PyTorch {config['pytorch_version']} ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“")
            errors.append(f"åˆ©ç”¨å¯èƒ½: {', '.join(cuda_info.get('pytorch_versions', []))}")
    
    # Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
    valid_python = ["3.9", "3.10", "3.11", "3.12"]
    if config['python_version'] not in valid_python:
        errors.append(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³: {config['python_version']}")
        errors.append(f"åˆ©ç”¨å¯èƒ½: {', '.join(valid_python)}")
    
    if errors:
        print("âŒ è¨­å®šã‚¨ãƒ©ãƒ¼:")
        for error in errors:
            print(f"  - {error}")
        sys.exit(1)
    
    print("âœ… è¨­å®šæ¤œè¨¼OK")

def generate_dockerfile(config):
    """Dockerfileã‚’ç”Ÿæˆ"""
    
    # PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨URLã‚’å–å¾—
    cuda_info = CUDA_PYTORCH[config['cuda_version']]
    pytorch_version = config.get('pytorch_version', cuda_info['default'])
    
    # äº’æ›æ€§ç¢ºèª
    if pytorch_version not in cuda_info['pytorch_versions']:
        print(f"âš ï¸  è­¦å‘Š: PyTorch {pytorch_version} ã¯ CUDA {config['cuda_version']} ã§æœªæ¤œè¨¼ã§ã™")
        pytorch_version = cuda_info['default']
        print(f"  â†’ PyTorch {pytorch_version} ã‚’ä½¿ç”¨ã—ã¾ã™")
    
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã‚€
    template_path = os.path.join('templates', 'Dockerfile.j2')
    with open(template_path, 'r') as f:
        template = Template(f.read())
    
    # è¨­å®šã‚’æº–å‚™
    render_config = {
        'cuda_version': config['cuda_version'],
        'cuda_short': config['cuda_version'].replace('.', ''),
        'python_version': config['python_version'],
        'pytorch_version': pytorch_version,
        'pytorch_index_url': cuda_info['index_url'],
        'transformers_version': config['transformers_version'],
        'packages': config['packages'],
        'claude_code': config.get('claude_code', False),
        'jupyter': config.get('jupyter', False),
        'mount_path': config.get('mount_path', '/workspace'),
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    # Dockerfileç”Ÿæˆ
    dockerfile_content = template.render(**render_config)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€
    with open('Dockerfile', 'w') as f:
        f.write(dockerfile_content)
    
    print(f"âœ… Dockerfileç”Ÿæˆå®Œäº†")
    return dockerfile_content

def build_image(config, name=None):
    """Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰"""
    image_name = name or f"llm-env:{config['cuda_version']}"
    
    print(f"ğŸ”¨ ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰ä¸­: {image_name}")
    print("  ï¼ˆåˆå›ã¯10-20åˆ†ã‹ã‹ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™ï¼‰")
    
    cmd = ["docker", "build", "-t", image_name, "."]
    result = subprocess.run(cmd)
    
    if result.returncode == 0:
        print(f"âœ… ãƒ“ãƒ«ãƒ‰æˆåŠŸ: {image_name}")
        
        # ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚µã‚¤ã‚ºã‚’è¡¨ç¤º
        size_cmd = ["docker", "images", image_name, "--format", "{{.Size}}"]
        size_result = subprocess.run(size_cmd, capture_output=True, text=True)
        if size_result.returncode == 0:
            print(f"ğŸ“¦ ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚µã‚¤ã‚º: {size_result.stdout.strip()}")
        
        return image_name
    else:
        print("âŒ ãƒ“ãƒ«ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)

def run_container(image=None, name=None):
    """Docker Composeã§ã‚³ãƒ³ãƒ†ãƒŠã‚’èµ·å‹•"""
    if os.path.exists('docker-compose.yaml'):
        print("ğŸš€ Docker Composeã§ã‚³ãƒ³ãƒ†ãƒŠã‚’èµ·å‹•ä¸­...")
        cmd = ["docker-compose", "up", "-d"]
        result = subprocess.run(cmd)
        
        if result.returncode == 0:
            print("âœ… ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•æˆåŠŸ")
            print("\nğŸ“ æ¥ç¶šæ–¹æ³•:")
            print("  docker exec -it llm-dev bash")
            print("\nğŸŒ ã‚µãƒ¼ãƒ“ã‚¹:")
            print("  Jupyter Lab: http://localhost:8888")
            print("  TensorBoard: http://localhost:6006")
        else:
            print("âŒ ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ")
    else:
        print("âš ï¸  docker-compose.yml ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("  é€šå¸¸ã®docker runã§èµ·å‹•ã—ã¾ã™...")
        
        config = load_config('config.yaml')
        container_name = name or config.get('container_name', 'llm-dev')
        image_name = image or f"llm-env:{config['cuda_version']}"
        
        # æ—¢å­˜ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’åœæ­¢
        subprocess.run(["docker", "stop", container_name], capture_output=True)
        subprocess.run(["docker", "rm", container_name], capture_output=True)
        
        cmd = [
            "docker", "run",
            "--gpus", "all",
            "--name", container_name,
            "-v", f"{os.getcwd()}:/workspace",
            "--shm-size", "16g",
            "-p", "8888:8888",
            "-p", "6006:6006",
            "-it",
            "-d",
            image_name
        ]
        
        result = subprocess.run(cmd)
        if result.returncode == 0:
            print(f"âœ… ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•æˆåŠŸ: {container_name}")

def list_packages(config):
    """é¸æŠã•ã‚ŒãŸãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    cuda_info = CUDA_PYTORCH[config['cuda_version']]
    pytorch_version = config.get('pytorch_version', cuda_info['default'])
    
    print("\nğŸ“¦ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:")
    print("\n  [åŸºæœ¬]")
    print(f"    âœ… PyTorch {pytorch_version} (CUDA {config['cuda_version']})")
    print(f"    âœ… Transformers {config['transformers_version']}")
    print("    âœ… NumPy, Pandas, Matplotlib")
    print("    âœ… Accelerate, Datasets, Hugging Face Hub")
    
    print("\n  [é¸æŠã•ã‚ŒãŸã‚ªãƒ—ã‚·ãƒ§ãƒ³]")
    for pkg, enabled in config['packages'].items():
        if enabled:
            info = PACKAGE_INFO.get(pkg, "")
            print(f"    âœ… {pkg}: {info}")
    
    if config.get('claude_code'):
        print("    âœ… Claude Code (Node.js 20 LTS)")
    
    if config.get('jupyter'):
        print("    âœ… Jupyter Lab")
    
    # æœªé¸æŠã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚‚è¡¨ç¤º
    print("\n  [æœªé¸æŠã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³]")
    for pkg, enabled in config['packages'].items():
        if not enabled:
            info = PACKAGE_INFO.get(pkg, "")
            print(f"    â¬œ {pkg}: {info}")

def main():
    parser = argparse.ArgumentParser(
        description="Simple LLM Docker Builder - ã‚·ãƒ³ãƒ—ãƒ«ã§å®Ÿç”¨çš„ãªLLMç’°å¢ƒæ§‹ç¯‰"
    )
    
    parser.add_argument(
        'command',
        choices=['init', 'validate', 'generate', 'build', 'run', 'all', 'list'],
        help='å®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰'
    )
    
    parser.add_argument('--config', default='config.yaml', help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«')
    parser.add_argument('--image', help='ã‚¤ãƒ¡ãƒ¼ã‚¸å')
    parser.add_argument('--name', help='ã‚³ãƒ³ãƒ†ãƒŠå')
    
    args = parser.parse_args()
    
    # initã‚³ãƒãƒ³ãƒ‰
    if args.command == 'init':
        init_config()
        return
    
    # è¨­å®šã‚’èª­ã¿è¾¼ã‚€
    if not os.path.exists(args.config):
        print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.config}")
        print("ğŸ’¡ ã¾ãš 'python build.py init' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        sys.exit(1)
    
    config = load_config(args.config)
    
    if args.command == 'validate':
        validate_config(config)
        print("âœ… è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã¯æœ‰åŠ¹ã§ã™")
    
    elif args.command == 'generate':
        validate_config(config)
        generate_dockerfile(config)
    
    elif args.command == 'build':
        validate_config(config)
        generate_dockerfile(config)
        build_image(config, args.image)
    
    elif args.command == 'run':
        run_container(args.image, args.name)
    
    elif args.command == 'list':
        list_packages(config)
    
    elif args.command == 'all':
        validate_config(config)
        list_packages(config)
        generate_dockerfile(config)
        image_name = build_image(config, args.image)
        run_container(image_name, args.name)
    
    print("\nâœ¨ å®Œäº†!")

if __name__ == "__main__":
    main()