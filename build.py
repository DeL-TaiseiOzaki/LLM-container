#!/usr/bin/env python3
"""
Simple LLM Docker Builder
ã‚·ãƒ³ãƒ—ãƒ«ã§å®Ÿç”¨çš„ãªLLMé–‹ç™ºç’°å¢ƒæ§‹ç¯‰ãƒ„ãƒ¼ãƒ«
"""

import os
import sys
import yaml
import argparse
import subprocess
from datetime import datetime
from jinja2 import Template

# CUDA-PyTorchå¯¾å¿œè¡¨ï¼ˆPyTorchå…¬å¼ã‚µã‚¤ãƒˆã‚ˆã‚Š 2025.1æœˆæ›´æ–°ï¼‰
CUDA_PYTORCH = {
    "11.8": {
        "pytorch_versions": ["2.7.0", "2.6.0", "2.5.1", "2.4.1", "2.3.1"],
        "default": "2.5.1",  # å®‰å®šç‰ˆã‚’æ¨å¥¨
        "index_url": "https://download.pytorch.org/whl/cu118"
    },
    "12.1": {
        "pytorch_versions": ["2.5.1", "2.4.1", "2.3.1"],
        "default": "2.5.1",
        "index_url": "https://download.pytorch.org/whl/cu121"
    },
    "12.4": {
        "pytorch_versions": ["2.6.0", "2.5.1", "2.4.1"],
        "default": "2.6.0",
        "index_url": "https://download.pytorch.org/whl/cu124"
    },
    "12.6": {
        "pytorch_versions": ["2.7.0", "2.6.0"],
        "default": "2.7.0",  # æœ€æ–°ç‰ˆ
        "index_url": "https://download.pytorch.org/whl/cu126"
    },
    "12.8": {
        "pytorch_versions": ["2.7.0"],
        "default": "2.7.0",  # H100ç”¨æœ€æ–°
        "index_url": "https://download.pytorch.org/whl/cu128"
    }
}

def load_config(config_path):
    """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
    with open(config_path, 'r') as f:
        return yaml.safe_load(f)

def validate_config(config):
    """è¨­å®šã‚’æ¤œè¨¼"""
    errors = []
    
    # CUDA ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
    if config['cuda_version'] not in CUDA_PYTORCH:
        errors.append(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„CUDAãƒãƒ¼ã‚¸ãƒ§ãƒ³: {config['cuda_version']}")
        errors.append(f"åˆ©ç”¨å¯èƒ½: {', '.join(sorted(CUDA_PYTORCH.keys()))}")
    
    # PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if 'pytorch_version' in config:
        cuda_info = CUDA_PYTORCH.get(config['cuda_version'], {})
        if config['pytorch_version'] not in cuda_info.get('pytorch_versions', []):
            errors.append(f"CUDA {config['cuda_version']}ã§ã¯ PyTorch {config['pytorch_version']} ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“")
            errors.append(f"åˆ©ç”¨å¯èƒ½: {', '.join(cuda_info.get('pytorch_versions', []))}")
    
    # Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯
    valid_python = ["3.9", "3.10", "3.11", "3.12"]
    if config['python_version'] not in valid_python:
        errors.append(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³: {config['python_version']}")
        errors.append(f"åˆ©ç”¨å¯èƒ½: {', '.join(valid_python)}")
    
    if errors:
        print("âŒ è¨­å®šã‚¨ãƒ©ãƒ¼:")
        for error in errors:
            print(f"  - {error}")
        sys.exit(1)
    
    print("âœ… è¨­å®šæ¤œè¨¼OK")

def generate_dockerfile(config):
    """Dockerfileã‚’ç”Ÿæˆ"""
    
    # PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨URLã‚’å–å¾—
    cuda_info = CUDA_PYTORCH[config['cuda_version']]
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®PyTorchãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å„ªå…ˆã€ãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’ä½¿ç”¨
    pytorch_version = config.get('pytorch_version', cuda_info['default'])
    
    # äº’æ›æ€§ç¢ºèª
    if pytorch_version not in cuda_info['pytorch_versions']:
        print(f"âš ï¸ è­¦å‘Š: PyTorch {pytorch_version} ã¯ CUDA {config['cuda_version']} ã§æœªæ¤œè¨¼ã§ã™")
        pytorch_version = cuda_info['default']
        print(f"  â†’ PyTorch {pytorch_version} ã‚’ä½¿ç”¨ã—ã¾ã™")
    
    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã‚€
    template_path = os.path.join('templates', 'Dockerfile.j2')
    with open(template_path, 'r') as f:
        template = Template(f.read())
    
    # è¨­å®šã‚’æº–å‚™
    render_config = {
        'cuda_version': config['cuda_version'],
        'cuda_short': config['cuda_version'].replace('.', ''),
        'python_version': config['python_version'],
        'pytorch_version': pytorch_version,
        'pytorch_index_url': cuda_info['index_url'],
        'transformers_version': config['transformers_version'],
        'packages': config['packages'],
        'claude_code': config.get('claude_code', False),
        'jupyter': config.get('jupyter', False),
        'mount_path': config.get('mount_path', '/workspace'),
        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    
    # Dockerfileç”Ÿæˆ
    dockerfile_content = template.render(**render_config)
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã‚€
    with open('Dockerfile', 'w') as f:
        f.write(dockerfile_content)
    
    print(f"âœ… Dockerfileç”Ÿæˆå®Œäº† (PyTorch {pytorch_version} with CUDA {config['cuda_version']})")
    return dockerfile_content

def build_image(config):
    """Dockerã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰"""
    image_name = f"llm-env:{config['cuda_version']}"
    
    print(f"ğŸ”¨ ã‚¤ãƒ¡ãƒ¼ã‚¸ã‚’ãƒ“ãƒ«ãƒ‰ä¸­: {image_name}")
    
    cmd = ["docker", "build", "-t", image_name, "."]
    result = subprocess.run(cmd)
    
    if result.returncode == 0:
        print(f"âœ… ãƒ“ãƒ«ãƒ‰æˆåŠŸ: {image_name}")
        return image_name
    else:
        print("âŒ ãƒ“ãƒ«ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ")
        sys.exit(1)

def run_container(config, image_name):
    """ã‚³ãƒ³ãƒ†ãƒŠã‚’èµ·å‹•"""
    container_name = config.get('container_name', 'llm-dev')
    mount_path = config.get('mount_path', '/workspace')
    
    # æ—¢å­˜ã®ã‚³ãƒ³ãƒ†ãƒŠã‚’åœæ­¢
    subprocess.run(["docker", "stop", container_name], capture_output=True)
    subprocess.run(["docker", "rm", container_name], capture_output=True)
    
    # ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•ã‚³ãƒãƒ³ãƒ‰
    cmd = [
        "docker", "run",
        "--gpus", "all",
        "--name", container_name,
        "-v", f"{os.path.expanduser('~')}:{mount_path}",
        "--shm-size", "8g",
        "-it",
        "-d",
        image_name,
        "/bin/bash"
    ]
    
    print(f"ğŸš€ ã‚³ãƒ³ãƒ†ãƒŠã‚’èµ·å‹•ä¸­: {container_name}")
    result = subprocess.run(cmd)
    
    if result.returncode == 0:
        print(f"âœ… ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•æˆåŠŸ: {container_name}")
        print(f"\nğŸ“ æ¥ç¶šæ–¹æ³•:")
        print(f"  docker exec -it {container_name} bash")
        if config.get('jupyter'):
            print(f"\nğŸŒ Jupyter Labèµ·å‹•:")
            print(f"  docker exec -it {container_name} jupyter lab --ip 0.0.0.0 --allow-root")
    else:
        print("âŒ ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ")

def list_packages(config):
    """é¸æŠã•ã‚ŒãŸãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’è¡¨ç¤º"""
    cuda_info = CUDA_PYTORCH[config['cuda_version']]
    pytorch_version = config.get('pytorch_version', cuda_info['default'])
    
    print("\nğŸ“¦ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸:")
    print("  [å¿…é ˆ]")
    print(f"    - PyTorch {pytorch_version} (CUDA {config['cuda_version']})")
    print(f"    - Transformers {config['transformers_version']}")
    
    print("  [ã‚ªãƒ—ã‚·ãƒ§ãƒ³]")
    for pkg, enabled in config['packages'].items():
        if enabled:
            print(f"    - {pkg}")
    
    if config.get('claude_code'):
        print("    - Claude Code")
    
    if config.get('jupyter'):
        print("    - Jupyter Lab")
    
    print(f"\nğŸ’¡ CUDA {config['cuda_version']} ã§åˆ©ç”¨å¯èƒ½ãªPyTorch:")
    for ver in cuda_info['pytorch_versions']:
        if ver == pytorch_version:
            print(f"    - {ver} â† é¸æŠä¸­")
        else:
            print(f"    - {ver}")

def main():
    parser = argparse.ArgumentParser(
        description="Simple LLM Docker Builder - ã‚·ãƒ³ãƒ—ãƒ«ã§å®Ÿç”¨çš„ãªLLMç’°å¢ƒæ§‹ç¯‰"
    )
    
    parser.add_argument(
        'command',
        choices=['build', 'run', 'all', 'list'],
        help='å®Ÿè¡Œã™ã‚‹ã‚³ãƒãƒ³ãƒ‰'
    )
    
    parser.add_argument(
        '--config',
        default='config.yaml',
        help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ (default: config.yaml)'
    )
    
    args = parser.parse_args()
    
    # è¨­å®šã‚’èª­ã¿è¾¼ã‚€
    if not os.path.exists(args.config):
        print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.config}")
        sys.exit(1)
    
    config = load_config(args.config)
    
    # è¨­å®šã‚’æ¤œè¨¼
    validate_config(config)
    
    if args.command == 'list':
        list_packages(config)
    
    elif args.command == 'build':
        generate_dockerfile(config)
        image_name = build_image(config)
    
    elif args.command == 'run':
        image_name = f"llm-env:{config['cuda_version']}"
        run_container(config, image_name)
    
    elif args.command == 'all':
        list_packages(config)
        generate_dockerfile(config)
        image_name = build_image(config)
        run_container(config, image_name)
    
    print("\nâœ¨ å®Œäº†!")

if __name__ == "__main__":
    main()