version: '3.8'

services:
  llm-dev:
    build: .
    image: llm-env:latest
    container_name: toe-esashi
    hostname: llm-dev
    
    # GPUサポート
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    # ボリューム
    volumes:
      - ./workspace:/workspace
      - ~/.cache/huggingface:/root/.cache/huggingface
      - ~/.cache/pip:/root/.cache/pip
    
    # 環境変数
    environment:
      - TRANSFORMERS_CACHE=/root/.cache/huggingface
      - HF_HOME=/root/.cache/huggingface
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - WANDB_API_KEY=${WANDB_API_KEY:-}
      - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN:-}
    
    # ポート
    ports:
      - "8888:8888"  # Jupyter Lab
      - "6006:6006"  # TensorBoard
      - "5000:5000"  # MLflow
      - "8000:8000"  # vLLM/FastAPI
    
    # 共有メモリ（GPUメモリ管理用）
    shm_size: "16gb"
    
    # 対話モード
    stdin_open: true
    tty: true
    
    # 再起動ポリシー
    restart: unless-stopped