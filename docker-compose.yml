version: '3.10'

services:
  llm-dev:
    build: .
    image: llm-env:latest
    container_name: llm-${USER:-dev}
    
    # GPU全部使う
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    # ボリューム（リポジトリ配下のユーザー別ディレクトリ）
    volumes:
      - ${BASE_DIR}/workspace:/workspace
      - ${BASE_DIR}/models:/models
      - ${BASE_DIR}/datasets:/datasets
      - ${BASE_DIR}/logs:/logs
      - /data/cache/huggingface:/cache/huggingface
      - /data/cache/uv:/cache/uv
    
    # 全ポート利用可能（ホストネットワークモード）
    network_mode: host
    
    # 環境変数（必要最小限）
    environment:
      - HF_HOME=/cache/huggingface
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - HF_TOKEN=${HF_TOKEN:-}
    
    stdin_open: true
    tty: true
    restart: unless-stopped