version: '3.8'

services:
  llm-dev:
    build: .
    image: llm-env:latest
    container_name: llm-${USER:-dev}
    
    # GPU全部使う
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    
    # ボリューム（リポジトリ配下のユーザー別ディレクトリ）
    volumes:
      - ./users/${USER}/workspace:/workspace
      - ./users/${USER}/models:/models
      - ./users/${USER}/datasets:/datasets
      - ./users/${USER}/logs:/logs
      - ~/.cache/huggingface:/root/.cache/huggingface
    
    # 全ポート利用可能（ホストネットワークモード）
    network_mode: host
    
    # 環境変数（必要最小限）
    environment:
      - HF_HOME=/root/.cache/huggingface
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY:-}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - HF_TOKEN=${HF_TOKEN:-}
    
    stdin_open: true
    tty: true
    restart: unless-stopped