#!/bin/bash

# Simple Multi-User LLM Container Launcher
# ä½¿ã„æ–¹: ./run.sh ãƒ¦ãƒ¼ã‚¶ãƒ¼å [GPUã‚ªãƒ—ã‚·ãƒ§ãƒ³] [ãƒãƒ¼ãƒˆã‚ªãƒ•ã‚»ãƒƒãƒˆ]

set -e

# ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
USER=${1:-$(whoami)}
GPU=${2:-all}
PORT_OFFSET=${3:-0}

# åŸºæœ¬è¨­å®š
CONTAINER="llm-${USER}"
IMAGE="llm-env:latest"
JUPYTER_PORT=$((8888 + PORT_OFFSET))
TENSORBOARD_PORT=$((6006 + PORT_OFFSET))

echo "ğŸš€ LLM Container for ${USER}"
echo "  Container: ${CONTAINER}"
echo "  GPU: ${GPU}"
echo "  Jupyter: http://localhost:${JUPYTER_PORT}"
echo "  TensorBoard: http://localhost:${TENSORBOARD_PORT}"
echo ""

# æ—¢å­˜ã‚³ãƒ³ãƒ†ãƒŠãƒã‚§ãƒƒã‚¯
if docker ps -a --format '{{.Names}}' | grep -q "^${CONTAINER}$"; then
    if docker ps --format '{{.Names}}' | grep -q "^${CONTAINER}$"; then
        echo "âš ï¸  æ—¢ã«å®Ÿè¡Œä¸­ã§ã™"
        echo "æ¥ç¶š: docker exec -it ${CONTAINER} bash"
        exit 0
    fi
    echo "å†èµ·å‹•ä¸­..."
    docker start ${CONTAINER}
    exit 0
fi

# ãƒ¯ãƒ¼ã‚¯ã‚¹ãƒšãƒ¼ã‚¹ä½œæˆ
mkdir -p workspace/${USER}
mkdir -p cache/${USER}

# GPUè¨­å®š
if [ "${GPU}" = "all" ]; then
    GPU_FLAG="--gpus all"
else
    GPU_FLAG="--gpus device=${GPU}"
fi

# ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•
docker run ${GPU_FLAG} \
  --name ${CONTAINER} \
  -v $(pwd)/workspace/${USER}:/workspace \
  -v $(pwd)/cache/${USER}:/root/.cache \
  -p ${JUPYTER_PORT}:8888 \
  -p ${TENSORBOARD_PORT}:6006 \
  --shm-size 16g \
  -e USER=${USER} \
  --hostname ${CONTAINER} \
  -it -d \
  ${IMAGE}

echo "âœ… èµ·å‹•å®Œäº†"
echo "æ¥ç¶š: docker exec -it ${CONTAINER} bash"